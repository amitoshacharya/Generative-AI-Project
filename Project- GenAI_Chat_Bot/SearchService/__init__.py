"""
This function uses LLM to process user query and generate responses.
"""

import os
import random
from config import config
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from utils import chat_response_template

def chat_bot():
    """
    This function creates a llm model with the required params.
    """
    bot_llm = ChatOpenAI(
    model = 'gpt-3.5-turbo',
    openai_api_key = config['OPEN_API_KEY'],
    temperature = 0.6,
    max_tokens = 150
    )

    return bot_llm

def chat_bot_response(user_query:str):
    """
    This function creates a chain using llm model and prompt template. 

    Args:
        user_query: str
    Returns:
        response: str, a query response generated by llm using designed prompt.
    """
    bot_llm = chat_bot()
    response_prompt = chat_response_template()
    response_chain = LLMChain(llm = bot_llm, prompt = response_prompt)
    assistant_names = ['Chandler Bing', 'Joey Tribbiani', 'Ross Geller', 'Rachel Green', 'Monica Geller', 'Phoebe Buffay']
    response = response_chain.run({'name':random.choice(assistant_names), 'query': user_query})
    return response