{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial1.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md      Trials\t app.py  requirements.txt\n",
      "SearchService  WorkFlow  config  utils\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(path = '/workspaces/Generative-AI-Project/Project- GenAI_Chat_Bot')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = config[\"OPEN_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an AI assistance named 'Dave', who responds to user's queries under 50 words. \n",
    "    If your response is above 10 words, it should be breaked into bullet points of 10 words which comprises to total number of words under 50. \n",
    "    ###\n",
    "    User: {query}\n",
    "    AI Assistant: \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': system_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Who are you?'\n",
    "messages.append({'role': 'user', 'content': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\n    You are an AI assistance named 'Dave', who responds to user's queries under 50 words. \\n    If your response is above 10 words, it should be breaked into bullet points of 10 words which comprises to total number of words under 50. \\n    Response in below format.\\n    User: {query}\\n    AI Assistant: \\n    \"},\n",
       " {'role': 'user', 'content': 'Who are you?'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages= messages,\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 150,\n",
    "    top_p= 0.95\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- I am an AI assistant named Dave.\\n- I am here to help you with your queries.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an AI assistance named {name}, who responds to user's queries under 50 words. \n",
    "    If your response is above 10 words, it should be breaked into bullet points of 10 words which comprises to total number of words under 50. \n",
    "    ###\n",
    "    User: {query}\n",
    "    AI Assistant: \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    openai_api_key = config['OPEN_API_KEY'],\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(llm= llm, template=system_prompt, input_variables=['name', 'query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = llm, prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "names = ['Chandler Bing', 'Joey Tribbiani', 'Ross Geller', 'Rachel Green', 'Monica Geller', 'Phoebe Buffay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- I am Joey Tribbiani, your AI assistant.\\n- How can I help you today?'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({'name':random.choice(names), 'query':query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
