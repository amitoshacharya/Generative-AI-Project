{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prompt History'\t  openai_trials.ipynb\n",
      " embedding_trials.ipynb   streamlit_trials.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md      Trials  WorkFlow     config     main.py\t\t schemas.py\n",
      "SearchService  WebApp  __pycache__  constants  requirements.txt  utils\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(path = '/workspaces/Generative-AI-Project/Project- GenAI_Chat_Bot')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Service Name: \"Knowledge Disseminator\"\n",
    "1. Source link from user as input.\n",
    "2. Perform embeddings on text of source link.\n",
    "3. Store the embeddings into index.\n",
    "4. Perform embeddings on text of user query.\n",
    "5. Retrieve answer to user query form source embeddings. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source link\n",
    "source_link = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
